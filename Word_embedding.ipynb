{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/abunickabhi/IRproject/blob/master/Word_embedding.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "nqGwS5O9efPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "outputId": "028ab400-cbcd-4ec3-92a7-f80f27a6a255"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abunickabhi/IRproject.git ; rm -rf embed/ ;mkdir embed ;cd IRproject/ ; git pull origin\n",
        "!pip3 install Cython\n",
        "!pip3 install word2vec\n",
        "!pip3 install fasttext\n",
        "!pip3 install gensim\n",
        "!pip3 install torch\n",
        "!pip3 install PyDictionary\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'IRproject' already exists and is not an empty directory.\n",
            "remote: Counting objects: 3, done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/abunickabhi/IRproject\n",
            "   e43a63e..03485aa  master     -> origin/master\n",
            "Updating e43a63e..03485aa\n",
            "Fast-forward\n",
            " Embedding_Reference.pdf | Bin \u001b[31m0\u001b[m -> \u001b[32m634800\u001b[m bytes\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " create mode 100644 Embedding_Reference.pdf\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: word2vec in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from word2vec)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from word2vec)\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from fasttext)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.6/dist-packages (from fasttext)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: botocore<1.11.0,>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: python-dateutil<2.7.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.4->boto3->smart-open>=1.2.1->gensim)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch)\n",
            "Requirement already satisfied: PyDictionary in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: goslate in /usr/local/lib/python3.6/dist-packages (from PyDictionary)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from PyDictionary)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from PyDictionary)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from PyDictionary)\n",
            "Requirement already satisfied: futures in /usr/local/lib/python3.6/dist-packages (from goslate->PyDictionary)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->PyDictionary)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "adv7d_lwmRfi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Importing all the required libraries**"
      ]
    },
    {
      "metadata": {
        "id": "gr0ljkD8YuQq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import word2vec\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "#from src.dictionary import Dictionary\n",
        "from PyDictionary import PyDictionary\n",
        "from torch import optim\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dmj4zmH0nEJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Sync the dataset in the Google Drive into the notebook environment**"
      ]
    },
    {
      "metadata": {
        "id": "_-NWeLYJnSdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f1605288-a976-4398-9199-ae444b2eae3c"
      },
      "cell_type": "code",
      "source": [
        "'''from google.colab import files\n",
        "import io\n",
        "\n",
        "a=files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "df = pd.read_csv(io.StringIO(uploaded['english.vec'].decode('utf-8')))\n",
        "print(df)\n",
        "'''"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from google.colab import files\\nimport io\\n\\na=files.upload()\\nfor fn in uploaded.keys():\\n  print(\\'User uploaded file \"{name}\" with length {length} bytes\\'.format(name=fn, length=len(uploaded[fn])))\\ndf = pd.read_csv(io.StringIO(uploaded[\\'english.vec\\'].decode(\\'utf-8\\')))\\nprint(df)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "rHxdR8nfr4Hy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Attempting to sync the dataset in the Google Drive by FUSE**"
      ]
    },
    {
      "metadata": {
        "id": "lD_bbuBRr9rc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "90bd7eef-6456-42fc-c8a8-1ca635187fa9"
      },
      "cell_type": "code",
      "source": [
        "'''# Install a Drive FUSE wrapper.\n",
        "# https://github.com/astrada/google-drive-ocamlfuse\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# Generate auth tokens for Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Generate creds for the Drive FUSE library.\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# Create a directory and mount Google Drive using that directory.\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "print 'Files in Drive:'\n",
        "!ls drive/\n",
        "\n",
        "# Create a file in Drive.\n",
        "!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt\n",
        "'''"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Install a Drive FUSE wrapper.\\n# https://github.com/astrada/google-drive-ocamlfuse\\n!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\\n!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\\n!apt-get update -qq 2>&1 > /dev/null\\n!apt-get -y install -qq google-drive-ocamlfuse fuse\\n\\n# Generate auth tokens for Colab\\nfrom google.colab import auth\\nauth.authenticate_user()\\n\\n# Generate creds for the Drive FUSE library.\\nfrom oauth2client.client import GoogleCredentials\\ncreds = GoogleCredentials.get_application_default()\\nimport getpass\\n!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\\nvcode = getpass.getpass()\\n!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\\n\\n# Create a directory and mount Google Drive using that directory.\\n!mkdir -p drive\\n!google-drive-ocamlfuse drive\\n\\nprint \\'Files in Drive:\\'\\n!ls drive/\\n\\n# Create a file in Drive.\\n!echo \"This newly created file will appear in your Drive file list.\" > drive/created.txt\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "mATomXqcldnD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading and Processing the source words i.e. English**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "dUSdLmj3o5qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "634658ca-81b9-41e4-e8c2-0973397f67d7"
      },
      "cell_type": "code",
      "source": [
        "max_vocab = 10000\n",
        "emb_dim = 300\n",
        "src_lang = 'eng'\n",
        "\n",
        "src_word2id = {}\n",
        "src_embeddings = []\n",
        "a= 'IRproject/reduced_English.vec'\n",
        "\n",
        "with open(a) as f:\n",
        "    for i,line in enumerate(f):\n",
        "        if i==0:\n",
        "            split = line.split()\n",
        "            assert len(split) == 2\n",
        "            assert emb_dim == int(split[1])\n",
        "        else:\n",
        "            word, vect = line.rstrip().split(' ', 1)\n",
        "            vect = np.fromstring(vect, sep=' ')\n",
        "            if np.linalg.norm(vect)==0: #to avoid null embeddings\n",
        "                vect[0] = 0.01\n",
        "            assert word not in src_word2id\n",
        "            assert vect.shape == (emb_dim, )\n",
        "            src_word2id[word] = len(src_word2id)\n",
        "            src_embeddings.append(vect[None,:])\n",
        "        if i > max_vocab:\n",
        "            break\n",
        "            \n",
        "src_id2word = {v: k for k,v in src_word2id.items()}\n",
        "src_embeddings = np.concatenate(src_embeddings,0)\n",
        "src_embeddings = torch.from_numpy(src_embeddings).float()\n",
        "src_emb = nn.Embedding(len(src_word2id), emb_dim, sparse=True)\n",
        "src_emb.weight.data.copy_(src_embeddings)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              " 0.1073  0.0089  0.0006  ...   0.0050  0.1173 -0.0400\n",
              " 0.0897  0.0160 -0.0571  ...   0.1559 -0.0254 -0.0259\n",
              " 0.0004  0.0032 -0.0204  ...   0.2070  0.0689 -0.0467\n",
              "          ...             ⋱             ...          \n",
              "-0.0675  0.0383 -0.0183  ...  -0.3375  0.0463 -0.0164\n",
              " 0.0806 -0.0063  0.0875  ...   0.2192  0.0188 -0.0608\n",
              "-0.0583  0.0550 -0.0072  ...  -0.2309 -0.0549  0.0410\n",
              "[torch.FloatTensor of size 13x300]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "XQK9ppSIklmb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Loading the source language i.e. Tamil into a Dictionary**"
      ]
    },
    {
      "metadata": {
        "id": "5e41SBCbpJos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "829cc62b-a06c-461c-cc04-f1a70247a0f7"
      },
      "cell_type": "code",
      "source": [
        "#src_dico = Dictionary(src_id2word, src_word2id, src_lang)\n",
        "\n",
        "tgt_lang = 'ta'\n",
        "tgt_word2id = {}\n",
        "tgt_embeddings = []\n",
        "b= 'IRproject/reduced_Tamil.vec'\n",
        "\n",
        "with open(b) as f:\n",
        "    for i,line in enumerate(f):\n",
        "        if i==0:\n",
        "            split = line.split()\n",
        "            assert len(split) == 2\n",
        "            assert emb_dim == int(split[1])\n",
        "        else:\n",
        "            word, vect = line.rstrip().split(' ', 1)\n",
        "            vect = np.fromstring(vect, sep=' ')\n",
        "            if np.linalg.norm(vect)==0: #to avoid null embeddings\n",
        "                vect[0] = 0.01\n",
        "            assert word not in tgt_word2id\n",
        "            assert vect.shape == (emb_dim, )\n",
        "            tgt_word2id[word] = len(tgt_word2id)\n",
        "            tgt_embeddings.append(vect[None,:])\n",
        "        if i > max_vocab:\n",
        "            break\n",
        "\n",
        "tgt_id2word = {v:k for k,v in tgt_word2id.items()}\n",
        "\n",
        "#tgt_dico = PyDictionary(tgt_id2word, tgt_word2id, tgt_lang)\n",
        "tgt_embeddings = np.concatenate(tgt_embeddings,0)\n",
        "tgt_embeddings = torch.from_numpy(tgt_embeddings).float()\n",
        "tgt_emb = nn.Embedding(len(tgt_word2id), emb_dim, sparse=True)\n",
        "tgt_emb.weight.data.copy_(tgt_embeddings)\n",
        "\n",
        "mapping = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "mapping.weight.data.copy_(torch.diag(torch.ones(emb_dim)))\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "    1     0     0  ...      0     0     0\n",
              "    0     1     0  ...      0     0     0\n",
              "    0     0     1  ...      0     0     0\n",
              "       ...          ⋱          ...       \n",
              "    0     0     0  ...      1     0     0\n",
              "    0     0     0  ...      0     1     0\n",
              "    0     0     0  ...      0     0     1\n",
              "[torch.FloatTensor of size 300x300]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "d8PAfLi48Lxs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Create a self class in Discriminator class and define the parameters of training**"
      ]
    },
    {
      "metadata": {
        "id": "s7DTT7W5pmik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14a301f4-5ace-4cc9-c86e-c40c015bea34"
      },
      "cell_type": "code",
      "source": [
        "disc_layers = 2\n",
        "disc_dim_hidden = 2048\n",
        "disc_dropout = 0\n",
        "disc_inp_dropout = 0.1\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.emb_dim = emb_dim\n",
        "        self.disc_layers = disc_layers\n",
        "        self.disc_dim_hidden = disc_dim_hidden\n",
        "        self.disc_dropout = disc_dropout\n",
        "        self.disc_inp_dropout = disc_inp_dropout\n",
        "        \n",
        "        layers = [nn.Dropout(self.disc_inp_dropout)]\n",
        "        for i in range(self.disc_layers + 1):\n",
        "            input_dim = self.emb_dim if i == 0 else self.disc_dim_hidden\n",
        "            output_dim = 1 if i==self.disc_layers else self.disc_dim_hidden\n",
        "            layers.append(nn.Linear(input_dim, output_dim))\n",
        "            if i < self.disc_layers:\n",
        "                layers.append(nn.LeakyReLU(0.2))\n",
        "                layers.append(nn.Dropout(self.disc_dropout))\n",
        "        layers.append(nn.Sigmoid())\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.layers(x).view(-1)\n",
        "      \n",
        "discriminator = Discriminator()\n",
        "'''\n",
        "src_emb.cuda()\n",
        "tgt_emb.cuda()\n",
        "mapping.cuda()\n",
        "discriminator.cuda()\n",
        "'''"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsrc_emb.cuda()\\ntgt_emb.cuda()\\nmapping.cuda()\\ndiscriminator.cuda()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "GZeIgNEF9Lmz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Use Stochastic Gradient Optimizer from Torch optim library to get source and target prediction and accuracy score**"
      ]
    },
    {
      "metadata": {
        "id": "GbPxakEj8bJH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "****"
      ]
    },
    {
      "metadata": {
        "id": "WlR41Zw0t3xe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optim_fn = optim.SGD\n",
        "optim_params = {'lr': 0.1}\n",
        "\n",
        "map_optimizer = optim_fn(mapping.parameters(), **optim_params)\n",
        "disc_optimizer = optim_fn(discriminator.layers.parameters(), **optim_params)\n",
        "epoch_size = 1000000\n",
        "batch_size = 32\n",
        "disc_steps = 5\n",
        "disc_most_freq = 75000\n",
        "disc_smooth = 0.1\n",
        "map_beta = 0.001\n",
        "\n",
        "def get_disc_xy(volatile):\n",
        "    \"\"\"\n",
        "    Get discriminator input batch / output target.\n",
        "    \"\"\"\n",
        "    # select random word IDs\n",
        "    bs = batch_size\n",
        "    mf = disc_most_freq\n",
        "    assert mf <= min(len(src_dico), len(tgt_dico))\n",
        "    src_ids = torch.LongTensor(bs).random_(mf)\n",
        "    tgt_ids = torch.LongTensor(bs).random_(mf)\n",
        "    src_ids = src_ids.cuda()\n",
        "    tgt_ids = tgt_ids.cuda()\n",
        "\n",
        "    # get word embeddings\n",
        "    src_emb = src_emb(Variable(src_ids, volatile=True))\n",
        "    tgt_emb = tgt_emb(Variable(tgt_ids, volatile=True))\n",
        "    src_emb = mapping(Variable(src_emb.data, volatile=volatile))\n",
        "    tgt_emb = Variable(tgt_emb.data, volatile=volatile)\n",
        "\n",
        "    # input / target\n",
        "    x = torch.cat([src_emb, tgt_emb], 0)\n",
        "    y = torch.FloatTensor(2 * bs).zero_()\n",
        "    y[:bs] = 1 - disc_smooth\n",
        "    y[bs:] = dis_smooth\n",
        "    y = Variable(y.cuda())\n",
        "\n",
        "    return x, y\n",
        "  \n",
        "def orthogonalize():\n",
        "  \n",
        "    W = mapping.weight.data\n",
        "    beta = map_beta\n",
        "    W.copy_((1 + beta) * W - beta * W.mm(W.transpose(0, 1).mm(W)))\n",
        "    \n",
        " \n",
        "def eval_dis(self, to_log):\n",
        "  \n",
        "    bs = 128\n",
        "    src_preds = []\n",
        "    tgt_preds = []\n",
        "\n",
        "    discriminator.eval()\n",
        "\n",
        "    for i in range(0, src_emb.num_embeddings, bs):\n",
        "        emb = Variable(src_emb.weight[i:i + bs].data, volatile=True)\n",
        "        preds = discriminator(mapping(emb))\n",
        "        src_preds.extend(preds.data.cpu().tolist())\n",
        "\n",
        "    for i in range(0,tgt_emb.num_embeddings, bs):\n",
        "        emb = Variable(tgt_emb.weight[i:i + bs].data, volatile=True)\n",
        "        preds = discriminator(emb)\n",
        "        tgt_preds.extend(preds.data.cpu().tolist())\n",
        "\n",
        "    src_pred = np.mean(src_preds)\n",
        "    tgt_pred = np.mean(tgt_preds)\n",
        "    print(\"Discriminator source / target predictions: %.5f / %.5f\"\n",
        "                % (src_pred, tgt_pred))\n",
        "\n",
        "    src_accu = np.mean([x >= 0.5 for x in src_preds])\n",
        "    tgt_accu = np.mean([x < 0.5 for x in tgt_preds])\n",
        "    dis_accu = ((src_accu * src_emb.num_embeddings + tgt_accu * tgt_emb.num_embeddings) /\n",
        "                    (src_emb.num_embeddings + tgt_emb.num_embeddings))\n",
        "    print(\"Discriminator source / target / global accuracy: %.5f / %.5f / %.5f\"\n",
        "                    % (src_accu, tgt_accu, dis_accu))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zqW54Dpn9lSN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Adversarial Training**"
      ]
    },
    {
      "metadata": {
        "id": "K2Ax1lNBvtWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "51784987-6f0a-456b-fbb7-185087aaa884"
      },
      "cell_type": "code",
      "source": [
        "def adv_training(epochs):\n",
        "    for epoch in range(epochs):\n",
        "        n_words_proc = 0\n",
        "        for n_iter in range(0,epoch_size, batch_size):\n",
        "            for _ in range(disc_steps): # Discriminator training\n",
        "                discriminator.train() # sets the module in training mode ex adds dropout and batchnorm\n",
        "                x,y = get_disc_xy(volatile=True)\n",
        "                preds = discriminator(Variable(x.data))\n",
        "                loss = F.binary_cross_entropy(preds,y)\n",
        "                disc_optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                disc_optimizer.step()\n",
        "                # Can add clipping if needed\n",
        "            \n",
        "            #Mapping step\n",
        "            discriminator.eval() # Puts the module in evaluation mode.\n",
        "            x, y = get_disc_xy(volatile=False)\n",
        "            preds = discriminator(Variable(x.data))\n",
        "            loss = F.binary_cross_entropy(preds, 1-y)\n",
        "            map_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            map_optmizer.step()\n",
        "            orthogonalize()\n",
        "            n_words_proc += 2 * batch_size\n",
        "            \n",
        "        # embeddings / discriminator evaluation\n",
        "        eval_dis()\n",
        "\n",
        "\n",
        "exp_path = \"\"\n",
        "def export_embeddings(src_emb, tgt_emb, params):\n",
        "    \n",
        "    src_id2word = src_dico.id2word\n",
        "    tgt_id2word = tgt_dico.id2word\n",
        "    n_src = len(src_id2word)\n",
        "    n_tgt = len(tgt_id2word)\n",
        "    dim = src_emb.shape[1]\n",
        "    src_path = os.path.join(exp_path, 'vectors-%s.txt' % src_lang)\n",
        "    tgt_path = os.path.join(exp_path, 'vectors-%s.txt' % tgt_lang)\n",
        "    # source embeddings\n",
        "    with open(src_path, 'w') as f:\n",
        "        f.write(\"%i %i\\n\" % (n_src, dim))\n",
        "        for i in range(len(src_id2word)):\n",
        "            f.write(\"%s %s\\n\" % (src_id2word[i], \" \".join(str(x) for x in src_emb[i])))\n",
        "   # target embeddings\n",
        "    with open(tgt_path, 'w') as f:\n",
        "        f.write(\"%i %i\\n\" % (n_tgt, dim))\n",
        "        for i in range(len(tgt_id2word)):\n",
        "            f.write(\"%s %s\\n\" % (tgt_id2word[i], \" \".join(str(x) for x in tgt_emb[i])))\n",
        "'''          \n",
        "src_emb = mapping(src_emb.weight).data\n",
        "tgt_emb = tgt_emb.weight.data\n",
        "src_emb = src_emb / src_emb.norm(2, 1, keepdim=True).expand_as(src_emb)\n",
        "tgt_emb = tgt_emb / tgt_emb.norm(2, 1, keepdim=True).expand_as(tgt_emb)\n",
        "export_embeddings(src_emb.cpu().numpy(), tgt_emb.cpu().numpy(), self.params)\n",
        "'''"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'          \\nsrc_emb = mapping(src_emb.weight).data\\ntgt_emb = tgt_emb.weight.data\\nsrc_emb = src_emb / src_emb.norm(2, 1, keepdim=True).expand_as(src_emb)\\ntgt_emb = tgt_emb / tgt_emb.norm(2, 1, keepdim=True).expand_as(tgt_emb)\\nexport_embeddings(src_emb.cpu().numpy(), tgt_emb.cpu().numpy(), self.params)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}